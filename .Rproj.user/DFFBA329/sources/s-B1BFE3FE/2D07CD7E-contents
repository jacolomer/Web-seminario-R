---
title: "Comparación de medias entre dos grupos"
author: "Joaquín Alcañiz Colomer"
date: 2021-08-25
categories: ["Estadística"]
tags: ["Comparación de medias"]
output:
  blogdown::html_page:
    toc: true
    css: "/css/my-style.css"
leng: es-ES 
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>
  <link rel="stylesheet" href="C:/css/my-style.css" type="text/css" />

<div id="TOC">
<ul>
<li><a href="#simulando-los-datos-para-nuestro-ejemplo">0. Simulando los datos para nuestro ejemplo</a></li>
<li><a href="#paquetes">1. Paquetes</a></li>
<li><a href="#homogeneidad-de-las-varianzas-y-normalidad">2. Homogeneidad de las varianzas y normalidad</a></li>
<li><a href="#diferencias-de-medias">3. Diferencias de medias</a></li>
<li><a href="#la-lógica-subyacente">4. La lógica subyacente</a></li>
<li><a href="#tamaño-del-efecto">5. Tamaño del efecto</a>
<ul>
<li><a href="#interpretar-y-transformar-el-tamaño-del-efecto">5.1. Interpretar y transformar el tamaño del efecto</a></li>
</ul></li>
<li><a href="#test-de-equivalencias">6. Test de equivalencias</a></li>
<li><a href="#representaciones-gráficas-de-diferencias-de-medias-y-distribuciones-de-dos-grupos">7. Representaciones gráficas de diferencias de medias y distribuciones de dos grupos</a>
<ul>
<li><a href="#barplot">7.1. Barplot</a></li>
<li><a href="#gráficos-de-violin">7.2. Gráficos de violin</a></li>
<li><a href="#otros-gráficos">7.3. Otros gráficos</a></li>
<li><a href="#guardar-los-gráficos">7.4. Guardar los gráficos</a></li>
</ul></li>
</ul>
</div>

<p>Para cualquier error que detectéis o sugerencia, podéis escribir a <a href="mailto:jcolomer@ugr.es" class="email">jcolomer@ugr.es</a></p>
<div id="simulando-los-datos-para-nuestro-ejemplo" class="section level1">
<h1>0. Simulando los datos para nuestro ejemplo</h1>
<p>Primero simulamos los datos, basándonos en los parámetros del primer estudio de <a href="https://science.sciencemag.org/content/332/6026/251.abstract?casa_token=VFzHSJ78wLwAAAAA:3oyCp3jtxNJJf7DBXch4CmNf0K6Q0Ttv2XXuQUZvgcnH6MQzNru95flX_vmsYO-j5X0WhhVwiezjcr_V">Stapel y Lindenberg (2011)</a> sobre cómo influye un contexto ordenado vs desordenado en la discriminación (también simulados, je). Esto es solo para tener unos datos con los que trabajar, en cada ejemplo se explica dónde tendríamos que situar nuestras variables.</p>
<pre class="r"><code>discrimination &lt;- (rnorm(n = 40, mean = 5.12, sd = 1.01)) #Generamos los datos para la primera media (del grupo 1)

data0 &lt;- as.data.frame(discrimination)

data0$condition &lt;- 1
  
discrimination &lt;- rnorm(n = 40, mean = 4.28, sd = 1.03) #Generamos los datos para la segunda media (del grupo 2)

data1 &lt;- as.data.frame(discrimination)

data1$condition &lt;- 2

data &lt;- rbind(data0, data1)

data$condition &lt;- factor(data$condition,
levels = c(1,2),
labels = c(&quot;Chaos condition&quot;, &quot;Order condition&quot;)) #añadimos etiquetas para las condiciones</code></pre>
</div>
<div id="paquetes" class="section level1">
<h1>1. Paquetes</h1>
<pre class="r"><code>library(effectsize) #Para calcular tamaños del efecto
library(ggstatsplot) #Para representaciones gráficas 
library(car) #Para comprobar homogeneidad varianzas con leveneTest()
library(dplyr) #Para algunas transformaciones de los datos
library(ggplot2)</code></pre>
<p>Utilizaremos otros paquetes en otros apartados, que irán apareciendo, pero de momento cargamos únicamente estos; hay que tener en cuenta que hay funciones que “solapan”.</p>
<p>Si no tenemos el paquete en la librería, antes del comando library(paquete) lo descargamos con install.packages(paquete).</p>
<p>Hay que tener en cuenta un par de cosas básicas:</p>
<ol style="list-style-type: decimal">
<li>En nuestro ejemplo, la variable dependiente se llama discrimination (las puntuaciones en la escala de discriminación) y la independiente se llama condicion (las dos condiciones que tenemos). Por tanto, para utilizar el código con nuestros datos tendremos que sustituir estos nombres por los nombres de nuestras variables en nuestra base de datos.</li>
<li>Cuando utilizamos el símbolo del dolar “$” después del nombre de nuestra base de datos estamos pidiendo al programa que busque dentro de esa base de datos. Luego ponemos la variable sobre la que queramso trabajar.</li>
</ol>
</div>
<div id="homogeneidad-de-las-varianzas-y-normalidad" class="section level1">
<h1>2. Homogeneidad de las varianzas y normalidad</h1>
<p>Para la normalidad, utilizamos el test de Shapiro:</p>
<pre class="r"><code>by(data$discrimination, data$condition, shapiro.test)</code></pre>
<pre><code>## data$condition: Chaos condition
## 
##  Shapiro-Wilk normality test
## 
## data:  dd[x, ]
## W = 0.96465, p-value = 0.2407
## 
## ------------------------------------------------------------ 
## data$condition: Order condition
## 
##  Shapiro-Wilk normality test
## 
## data:  dd[x, ]
## W = 0.99218, p-value = 0.9933</code></pre>
<p>Para comprobar la homogeneidad de las varianzas:</p>
<p>F-test:</p>
<pre class="r"><code>var.test(data$discrimination ~ data$condition) #F-test para comprobar la homogeneidad de las varianzas</code></pre>
<pre><code>## 
##  F test to compare two variances
## 
## data:  data$discrimination by data$condition
## F = 1.0857, num df = 39, denom df = 39, p-value = 0.7986
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.5742376 2.0527952
## sample estimates:
## ratio of variances 
##           1.085722</code></pre>
<p>Test de Levene. Por defecto utiliza la mediana (más robusto), pero podemos elegir la media con sustituyendo en el argumento center = “mean”</p>
<pre class="r"><code>leveneTest(y = data$discrimination, group = data$condition, center = &quot;median&quot;) </code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = &quot;median&quot;)
##       Df F value Pr(&gt;F)
## group  1  0.1493 0.7002
##       78</code></pre>
<p>Test de Barlett:</p>
<pre class="r"><code>bartlett.test(data$discrimination ~ data$condition)</code></pre>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  data$discrimination by data$condition
## Bartlett&#39;s K-squared = 0.065098, df = 1, p-value = 0.7986</code></pre>
<p>También podemos realizar el test de Brown-Forsyth con la función hov() del paquete HH o el Fligner-Killeen test utilizando la misma fórmula y la función fligner.test().</p>
<p>Si el resultado del test que elijamos es p &lt; .05 no podemos asumir que las varianzas son iguales. Estas pruebas apuntarían a que nuestros grupos las varianzas no son homogéneas y utilizaríamos pruebas distintas para calcular si hay diferencias significativas entre las medias.</p>
<p>Si utilizamos t.test() para las diferencias de medias el propio programa lleva a cabo una prueba (e.g. Two Sample t-test) u otra (e.g. Welch Two Sample t-test) en función de si hay igualdad de las varianzas, pero podemos forzarlo asumir igualdad de varianzas con el argumento var.equal = TRUE o a asumir lo contrario, con el argumento var.equal = FALSE. Por tanto, está bien tener control sobre lo que hacemos y elegir la mejor prueba, teniendo en cuanta nuestras consideraciones teóricas, para estudiar la homogeneidad de la varianza y, en consecuencia, el mejor test de comparación de medias.</p>
</div>
<div id="diferencias-de-medias" class="section level1">
<h1>3. Diferencias de medias</h1>
<pre class="r"><code>?t.test #para ver todos los argumentos que podemos añadir a la función. Por ejemplo, alternative = &quot;two.sided&quot; si queremos que la prueba sea bidireccional o de dos colas; alternative = &quot;greater&quot; unidireccional y esperamos que sea positivo el resultado; alternative = &quot;less&quot;, unidireccional y esperamos que sea negativo el resultado etc. </code></pre>
<p>Diferencia dos grupos independientes, asumiendo varianzas iguales:</p>
<pre class="r"><code>t.test(discrimination ~ condition, data = data, alternative = &quot;two.sided&quot;, var.equal = TRUE)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  discrimination by condition
## t = 4.4684, df = 78, p-value = 2.632e-05
## alternative hypothesis: true difference in means between group Chaos condition and group Order condition is not equal to 0
## 95 percent confidence interval:
##  0.6629921 1.7284715
## sample estimates:
## mean in group Chaos condition mean in group Order condition 
##                      5.467932                      4.272200</code></pre>
<p>Si no podemos asumir varianzas iguales:</p>
<pre class="r"><code>t.test(discrimination ~ condition, data = data, alternative = &quot;two.sided&quot;, var.equal = FALSE)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  discrimination by condition
## t = 4.4684, df = 77.868, p-value = 2.637e-05
## alternative hypothesis: true difference in means between group Chaos condition and group Order condition is not equal to 0
## 95 percent confidence interval:
##  0.6629779 1.7284857
## sample estimates:
## mean in group Chaos condition mean in group Order condition 
##                      5.467932                      4.272200</code></pre>
<p>Medidas repetidas</p>
<pre class="r"><code>t.test(discrimination ~ condition, data = data, alternative = &quot;two.sided&quot;, paired = TRUE, var.equal = TRUE)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  discrimination by condition
## t = 4.4683, df = 39, p-value = 6.593e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.6544559 1.7370077
## sample estimates:
## mean of the differences 
##                1.195732</code></pre>
<p>Si los datos no siguen una distribución normal, como test no paramétrico, podemos utilizar el de Wilcoxon:</p>
<pre class="r"><code>wilcox.test(data$discrimination ~ data$condition, alternative = &quot;two.sided&quot;, paired = FALSE) #Para medidas repetidas en el argumento paired escribiríamos TRUE</code></pre>
<pre><code>## 
##  Wilcoxon rank sum exact test
## 
## data:  data$discrimination by data$condition
## W = 1222, p-value = 3.008e-05
## alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div id="la-lógica-subyacente" class="section level1">
<h1>4. La lógica subyacente</h1>
<p>Este paso puede saltarse (hay que descargar varios paquetes y algunos usando ‘remotes’, hay mucho código, etc.), es simplemente para ilustrar de forma breve la lógica de una comparación de medias (y otros análisis estadísticos que hacemos).</p>
<p>El código de este apartado está copiado groseamente de una entrada del blog de <a href="https://www.andrewheiss.com/blog/2019/01/29/diff-means-half-dozen-ways/#t-test-assuming-equal-variances">Andrew Heiss</a>. La idea fundamental, y que aparece explicada tanto en el blog que cito antes como en este de <a href="http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html">Allen Downey</a>, es que para cualquier test estadístico hacemos lo siguiente:</p>
<ol style="list-style-type: decimal">
<li>Calcular un estadístico en nuestra muestra.</li>
<li>Simular una población donde nuestro estadístico es nulo (en este caso la diferencia de medias).</li>
<li>Comparar nuestro estadístico con la población en el que es nulo.</li>
<li>Calcular la probabilidad de que nuestro estadístico exista en la población ‘nula’.</li>
<li>Decidir si es significativo (usando normalmente el estándar de .05)</li>
</ol>
<p>Primero cargamos los paquetes necesarios</p>
<pre class="r"><code>library(infer) #Para las simulaciones
#install.packages(&quot;remotes&quot;) #Si no lo tenemos previamente instalado
remotes::install_github(&quot;brooke-watson/bplots&quot;)
library(bplots) #Para los gráficos
library(scales) #Para los gráficos</code></pre>
<p>Primero calculamos la diferencia de medias en nuestra muestra y la guardamos como un objeto.</p>
<pre class="r"><code>difmed &lt;- data %&gt;% 
  specify(discrimination ~ condition) %&gt;%
  calculate(&quot;diff in means&quot;, order = c(&quot;Chaos condition&quot;, &quot;Order condition&quot;))
difmed</code></pre>
<pre><code>## Response: discrimination (numeric)
## Explanatory: condition (factor)
## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  1.20</code></pre>
<p>Ahora calculamos el intervalo de confianza usando una distribución ‘bootstrapped’ de las diferencias de medias basada en nuestra muestra.</p>
<pre class="r"><code>medboot &lt;- data %&gt;% 
  specify(discrimination ~ condition) %&gt;% 
  generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% 
  calculate(&quot;diff in means&quot;, order = c(&quot;Chaos condition&quot;, &quot;Order condition&quot;))

boostrapped_confint &lt;- medboot %&gt;% get_confidence_interval()</code></pre>
<pre><code>## Using `level = 0.95` to compute confidence interval.</code></pre>
<pre class="r"><code>medboot %&gt;% 
  visualize() + 
  shade_confidence_interval(boostrapped_confint,
                            color = &quot;#8bc5ed&quot;, fill = &quot;#85d9d2&quot;) +
  geom_vline(xintercept = difmed$stat, size = 1, color = &quot;#77002c&quot;) +
  labs(title = &quot; Distribución &#39;bootstrapped&#39; de la diferencia de medias&quot;,
       x = &quot;Chaos condition - Order condition&quot;, y = &quot;Count&quot;,
       subtitle = &quot;La línea roja muestra la diferencia observada; la zona sombreada muestra el intervalo de confianza al 95%&quot;) +
  theme_fancy()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-14-1.png" width="8000" /></p>
<p>Ya tenemos calculado nuestro estadístico. Ahora simulamos un mundo donde este sea nulo y añadimos nuestro estadístico a esta población (lo representa la línea roja en el último gráfico de este apatado).</p>
<pre class="r"><code>#Generamos un &#39;mundo&#39; donde las diferencias son nulas. 
cond_diffs_null &lt;- data %&gt;% 
  specify(discrimination ~ condition) %&gt;% 
  hypothesize(null = &quot;independence&quot;) %&gt;% 
  generate(reps = 5000, type = &quot;permute&quot;) %&gt;% 
  calculate(&quot;diff in means&quot;, order = c(&quot;Chaos condition&quot;, &quot;Order condition&quot;))

#Ponemos nuestro valor observado en este mundo donde las diferencias son nulas para ver cómo de probable es
cond_diffs_null %&gt;% 
  visualize() + 
  geom_vline(xintercept = difmed$stat, size = 1, color = &quot;#77002c&quot;) +
  scale_y_continuous(labels = comma) +
  labs(x = &quot;Diferencia simulada en las medias de las puntuaciones (Chaos condition - order condition)&quot;, y = &quot;Count&quot;,
       title = &quot;Distribución nula de las diferencias de medias basada en la simulación&quot;,
       subtitle = &quot;La línea roja muestra la diferencia observada&quot;) +
  theme_fancy()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-15-1.png" width="8000" /></p>
<p>Vemos que parece muy poco probable observar este valor del estadístico en un mundo donde no haya diferencias entre los grupos.</p>
<pre class="r"><code>cond_diffs_null %&gt;% 
  get_p_value(obs_stat = difmed, direction = &quot;both&quot;) %&gt;% 
  mutate(p_value_clean = pvalue(p_value))</code></pre>
<pre><code>## # A tibble: 1 x 2
##   p_value p_value_clean
##     &lt;dbl&gt; &lt;chr&gt;        
## 1       0 &lt;0.001</code></pre>
</div>
<div id="tamaño-del-efecto" class="section level1">
<h1>5. Tamaño del efecto</h1>
<p>Parece que es poco probable obtener estos datos, o más extremos, si la hipótesis nula fuera cierta; nuestros datos parecen ir en línea con la idea de que los contextos desordenados (frente a los ordenados) favorecen las actitudes discriminatorias (!). Esto no es demasiado informativo por sí mismo, así que calculamos el tamaño del efecto para tener una idea de la magnitud de la relación entre la variable independiente y la dependiente.</p>
<p>Si asumimos que las varianzas son iguales y hemos realizado una prueba t de student, lo usual es utilizar la d de Cohen como estimador del tamaño del efecto, dividiendo la diferencia de medias por la desviación típica agrupada de la muestra <a href="https://link.springer.com/article/10.1007/s10648-013-9218-2">(Peng et al., 2013)</a>. Sin embargo, si no podemos asumir que las varianzas son iguales, últimamente se ha sugerido que es mejor utilizar la g de hedges <a href="https://psyarxiv.com/tu6mp/">(Delacre et al., 2021)</a>; además de utilizar el test de Welch anteriormente, claro.</p>
<pre class="r"><code>cohens_d(data$discrimination, y = data$condition, ci = 0.95, pooled_sd = TRUE) #Con pooled_sd = TRUE indicamos que utilice la desviación típica agrupada de ambas muestras. Asumimos que las varianzas son iguales. </code></pre>
<pre><code>## Cohen&#39;s d |       95% CI
## ------------------------
## 1.00      | [0.53, 1.46]
## 
## - Estimated using pooled SD.</code></pre>
<pre class="r"><code>hedges_g(data$discrimination, y = data$condition, ci = 0.95, pooled_sd = FALSE)</code></pre>
<pre><code>## Hedges&#39; g |       95% CI
## ------------------------
## 0.99      | [0.53, 1.45]
## 
## - Estimated using un-pooled SD.</code></pre>
<div id="interpretar-y-transformar-el-tamaño-del-efecto" class="section level2">
<h2>5.1. Interpretar y transformar el tamaño del efecto</h2>
<p>Utilizar puntos de referencia (benchmarks) para describir el tamaño del efecto que hemos encontrado (principalmente los de Cohen) puede ser problemático, en tanto que no tenemos en cuenta el marco de referencia específico en el que se da nuestro efecto, qué implicaciones puede tener, etc (para profundizar un poco más en la cuestión o la utilización benchmarks alternativos a los de Cohen se puede ver <a href="https://journals.sagepub.com/doi/full/10.1177/2515245919847202">Funder &amp; Ozer, 2019</a>). Una opción interesante puede ser utilizar guías que se basen en los tamaños del efecto encontrados en la investigación en psicología social (<a href="https://onlinelibrary.wiley.com/doi/full/10.1002/ejsp.2752?casa_token=PmPfBBvNPCkAAAAA%3AT1_sP2N3IYi9r14sUyov3O0_6agZCH1Ca_ysoURGjg9x_zraGhcs0gYCrkEPzdSUBfC-Rkq7A_xD0wtKHg">Lovakov &amp; Agadullina, 2021</a>). Lovakov y Aggadullina encuentran que los percentiles 25, 50 y 75, analizando 134 meta-análisis publicados, corresponden a valores de la d de Cohen de 0.15, 0.36 y 0.65 respectivamente y a un coeficiente de correlación de 0.12, 0.24 y 0.41.</p>
<p>Por lo tanto, lo siguiente no es tan relevante como lo anterior, pero podemos pedirle a R que nos interprete nuestro tamaño del efecto.</p>
<pre class="r"><code>interpret_d(1.10, rules = &quot;cohen1988&quot;) #Con las reglas de Cohen</code></pre>
<pre><code>## [1] &quot;large&quot;
## (Rules: cohen1988)</code></pre>
<pre class="r"><code>interpret_d(1.10, rules = &quot;lovakov2021&quot;) #Con los puntos de referencia de Lovakov y Agadullina (2021)</code></pre>
<pre><code>## [1] &quot;large&quot;
## (Rules: lovakov2021)</code></pre>
<p>También podemos transformar la d de Cohen a un coeficiente de correlación o viceversa, entre otras muchas opciones que se pueden consultar en las funciones del paquete effectsize</p>
<pre class="r"><code>d_to_r(1.10)</code></pre>
<pre><code>## [1] 0.4819187</code></pre>
</div>
</div>
<div id="test-de-equivalencias" class="section level1">
<h1>6. Test de equivalencias</h1>
<p>Para entender bien qué es un test de equivalencias se puede consultar <a href="https://journals.sagepub.com/doi/full/10.1177/1948550617697177">Lakens (2017)</a> y <a href="https://journals.sagepub.com/doi/full/10.1177/2515245918770963">Lakens, Scheel e Isager (2018)</a>, donde hay introducciones y guías muy accesibles para llevarlos a cabo; en concreto aquí nos interesan los TOST (“two one-sided test”). Una definición grosera y mucho menos exacta: la idea fundamental es establecer, a priori (antes de recoger los datos), un límite superior e inferior de equivalencia basándonos en el mínimo efecto de interés (SESOI) relevante para nuestra investigación (se pueden ver las posibilidades a la hora de especificar este, también una vez recogidos los datos, en Lakens et al., 2018). Si nuestro efecto cae entre esos intervalos podemos decir que está lo suficientemente cerca de cero para ser equivalente en la práctica. Hay que tener en cuenta que desde la estadística frecuentista no podemos decir que no haya efecto aunque el resultado de nuestro test (e.g. comparación de medias) no sea significativo.</p>
<p>Por ejemplo, en nuestro caso y siguiendo con la investigación de Stapel y Lindenberg (2011), podemos determinar nuestro SESOI como el tamaño del efecto que el estudio anterior pudiese detectar con un poder del 33% <a href="https://journals.sagepub.com/doi/full/10.1177/0956797614567341?casa_token=h5QriJpfjv8AAAAA%3Awbyl5p2W703wEgvkTuRyqPwewXG3iGGEYyc4kbm-0DiEFbJasPhMTguTnZnceDpU3XTH47R5hbdgSBs">(Simonsohn, 2015)</a>, que en este caso sería 0.34 (-0.34 para el límite inferior).</p>
<p>La función, del paquete TOSTER sería la siguiente:</p>
<p>TOSTtwo(m1, m2, sd1, sd2, n1, n2, low_eqbound_d, high_eqbound_d, alpha,
var.equal, plot = TRUE, verbose = TRUE)</p>
<p>Podemos consultar ?TOSTtwo para ver qué significa cada argumento, aunque son bastante autodescriptivos</p>
<pre class="r"><code>library(TOSTER) #El paquete necesario para los test de equivalencias

#Con nuestros datos#

TOSTtwo(m1 = 5.218811, m2 = 4.031867, sd1 = 1.088976, sd2 = 1.072184, n1 = 40, n2 = 40, low_eqbound_d = -0.34, high_eqbound_d = 0.34, alpha = 0.05, var.equal = TRUE, plot = TRUE, verbose = TRUE)</code></pre>
<pre><code>## TOST results:
## t-value lower bound: 6.43    p-value lower bound: 0.000000005
## t-value upper bound: 3.39    p-value upper bound: 0.999
## degrees of freedom : 78
## 
## Equivalence bounds (Cohen&#39;s d):
## low eqbound: -0.34 
## high eqbound: 0.34
## 
## Equivalence bounds (raw scores):
## low eqbound: -0.3674 
## high eqbound: 0.3674
## 
## TOST confidence interval:
## lower bound 90% CI: 0.785
## upper bound 90% CI:  1.589
## 
## NHST confidence interval:
## lower bound 95% CI: 0.706
## upper bound 95% CI:  1.668
## 
## Equivalence Test Result:
## The equivalence test was non-significant, t(78) = 3.392, p = 0.999, given equivalence bounds of -0.367 and 0.367 (on a raw scale) and an alpha of 0.05.</code></pre>
<pre><code>## </code></pre>
<pre><code>## 
## Null Hypothesis Test Result:
## The null hypothesis test was significant, t(78) = 4.912, p = 0.00000486, given an alpha of 0.05.</code></pre>
<pre><code>## </code></pre>
<pre><code>## 
## Based on the equivalence test and the null-hypothesis test combined, we can conclude that the observed effect is statistically different from zero and statistically not equivalent to zero.</code></pre>
<pre><code>## </code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre class="r"><code>#El mismo output nos describe los resultados, en este caso nos indica que el efecto no es estadísticamente equivalente a cero. </code></pre>
</div>
<div id="representaciones-gráficas-de-diferencias-de-medias-y-distribuciones-de-dos-grupos" class="section level1">
<h1>7. Representaciones gráficas de diferencias de medias y distribuciones de dos grupos</h1>
<p>Para representar estas diferencias hay varias opciones y las posibilidades de personalización en R son enormes, aquí únicamente ponemos algunos ejemplos con el código listo para utilizar.</p>
<div id="barplot" class="section level2">
<h2>7.1. Barplot</h2>
<pre class="r"><code>library(ggplot2) #Para generar los gráficos
library(ggpubr) #Para adaptar los gráficos al formato que queramos (hay otras opciones)

infograph &lt;- data %&gt;%
    group_by(condition) %&gt;%
    summarise( 
    n=n(),
    mean=mean(discrimination),
    sd=sd(discrimination)
  ) %&gt;%
  mutate( se=sd/sqrt(n))  %&gt;%
  mutate( ic=se * qt((1-0.05)/2 + .5, n-1))



pal &lt;- c(&quot;#009E73&quot;, &quot;#E69F00&quot;) #Generamos nuestra paleta colorblind friendly (hay mucha informacióne en Internet de cómo hacerlo, se puede usar el paquete RColorBrewer también)


barplt &lt;- ggplot(infograph) +
  geom_col(aes(x=condition, y=mean, fill = pal), alpha=1, width = 0.6) +
  scale_fill_manual(values = pal) +
  geom_errorbar(aes(x=condition, ymin=mean-ic, ymax=mean+ic), width=0.2, colour=&quot;black&quot;, alpha=0.9, size=0.5) +
  ggtitle(&quot;Differences between experimental conditions (using confidence intervals)&quot;) +
    xlab(&quot;Experimental Condition&quot;) + 
    ylab(&quot;Discrimination scores&quot;) 
  


barplt2 &lt;- barplt + theme_pubr(base_size = 10, border = FALSE, margin = TRUE, legend = &quot;none&quot;)

barplt2</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
</div>
<div id="gráficos-de-violin" class="section level2">
<h2>7.2. Gráficos de violin</h2>
<p>La forma más rápida de hacer un violin plot con bastante información es con ggbetweenstats, del paquete ggstatsplot</p>
<pre class="r"><code>ggbetweenstats(data = data, x = condition, y = discrimination)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code>#Tenemos muchas opciones para modificarlo

ggbetweenstats(
  data,
  condition,
  discrimination,
  plot.type = &quot;boxviolin&quot;,
  type = &quot;parametric&quot;,
  pairwise.comparisons = TRUE,
  pairwise.display = &quot;significant&quot;,
  p.adjust.method = &quot;holm&quot;,
  effsize.type = &quot;eta&quot;,
  bf.prior = 0.707,
  bf.message = TRUE,
  results.subtitle = TRUE,
  xlab = &quot;Condition&quot;,
  ylab = &quot;Discrimination&quot;,
  caption = NULL,
  title = &quot;Effect of disordered (vs ordered) context in discrimination scores&quot;,
  subtitle = NULL,
  k = 2L,
  var.equal = TRUE,
  conf.level = 0.95,
  nboot = 100L,
  tr = 0.2,
  centrality.plotting = TRUE,
  centrality.type = &quot;parametric&quot;,
    centrality.point.args = list(size = 5, color = &quot;darkred&quot;),
  centrality.label.args = list(size = 3, nudge_x = 0.4, segment.linetype = 4,
    min.segment.length = 0),
  outlier.tagging = FALSE,
  outlier.label = NULL,
  outlier.coef = 1.5,
  outlier.shape = 19,
  outlier.color = &quot;black&quot;,
  outlier.label.args = list(size = 3),
  point.args = list(position = ggplot2::position_jitterdodge(dodge.width = 0.4), alpha = 0.4, size = 2, stroke = 0),
  violin.args = list(width = 0.7, alpha = 0.5),
  ggsignif.args = list(textsize = 4, tip_length = 0.01),
  ggtheme = ggstatsplot::theme_ggstatsplot(),
  package = &quot;RColorBrewer&quot;,
  palette = &quot;Dark2&quot;,
  ggplot.component = NULL,
  output = &quot;plot&quot;) + xlab(&quot;Experimental Condition&quot;) + 
    ylab(&quot;Discrimination scores&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-22-2.png" width="672" /></p>
<p>Otra forma de hacer gráficos de violín:</p>
<pre class="r"><code>library(viridis)
library(hrbrthemes)

ggplot(data, aes(x=condition, y= discrimination, fill=condition)) + 
  geom_violin() +
  geom_boxplot(width=0.1, color=&quot;grey&quot;, alpha=0.5) +
  scale_fill_viridis(discrete = TRUE) +
    theme_ipsum() +
    theme(axis.line = element_line(colour = &quot;black&quot;),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    legend.position=&quot;none&quot;,
    plot.title = element_text(size=11)
      ) +
    ggtitle(&quot;Discrimination scores in both conditions&quot;) +
    xlab(&quot;&quot;) + 
    ylab(&quot;Discrimination scores&quot;) + 
  scale_fill_manual(values = c(&quot;#56B4E9&quot;, &quot;#D55E00&quot;)) +
  theme_pubr(base_size = 11, border = FALSE, margin = TRUE, legend = &quot;none&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Otra posibilidad más:</p>
<pre class="r"><code>library(gghalves)

ggplot(data, aes(x = condition, y = discrimination, fill = condition)) + 
  ggdist::stat_halfeye(
    adjust = .5, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA) + 
  geom_boxplot(
    width = .20, 
    outlier.shape = NA) + 
  geom_point(
    size = 2,
    alpha = .5,
    position = position_jitter(
      seed = 1, width = .1)) + 
  coord_cartesian(xlim = c(1.2, NA), clip = &quot;off&quot;) + 
  scale_fill_viridis(discrete = TRUE) +
    theme_ipsum() +
    theme(axis.line = element_line(colour = &quot;black&quot;),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
      legend.position=&quot;none&quot;,
      plot.title = element_text(size=11)
    ) +
    ggtitle(&quot;Discrimination scores in both conditions&quot;) +
    xlab(&quot;&quot;) + 
    ylab(&quot;Discrimination scores&quot;) + scale_fill_brewer(palette=&quot;Dark2&quot;) + scale_fill_manual(values = c(&quot;#56B4E9&quot;, &quot;#D55E00&quot;)) </code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Ahora incluyendo si las diferencias son significativas con el paquete ‘ggsignif’</p>
<pre class="r"><code>library(ggsignif)

ggplot(data, aes(x = condition, y = discrimination, fill = condition)) + 
  ggdist::stat_halfeye(
    adjust = .5, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA) + 
  geom_boxplot(
    width = .20, 
    outlier.shape = NA) + 
  geom_signif(
    comparisons = list(c(&quot;Chaos condition&quot;, &quot;Order condition&quot;)),
    map_signif_level = TRUE #Con estas líneas indicamos que queremos mostrar si las diferencias son significativas en el gráfico
  ) +
  geom_point(
    size = 2,
    alpha = .5,
    position = position_jitter(
      seed = 1, width = .1)) + 
  coord_cartesian(xlim = c(1.2, NA), clip = &quot;off&quot;) + 
  scale_fill_viridis(discrete = TRUE) +
    theme_ipsum() +
    theme(axis.line = element_line(colour = &quot;black&quot;),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
      legend.position=&quot;none&quot;,
      plot.title = element_text(size=11)
    ) +
    ggtitle(&quot;Discrimination scores in both conditions&quot;) +
    xlab(&quot;&quot;) + 
    ylab(&quot;Discrimination scores&quot;) + scale_fill_brewer(palette=&quot;Dark2&quot;) + scale_fill_manual(values = c(&quot;#56B4E9&quot;, &quot;#D55E00&quot;)) </code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>También podríamos incluir el resultado directamente con el paquete ‘statsExpressions’:</p>
<pre class="r"><code>library(statsExpressions)

expresion &lt;- two_sample_test(condition, discrimination, data = data, alternative = &quot;two.sided&quot;)

ggplot(data, aes(x = condition, y = discrimination, fill = condition)) + 
  ggdist::stat_halfeye(
    adjust = .5, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA) + 
  geom_boxplot(
    width = .20, 
    outlier.shape = NA) + 
  geom_point(
    size = 2,
    alpha = .5,
    position = position_jitter(
      seed = 1, width = .1)) + 
  coord_cartesian(xlim = c(1.2, NA), clip = &quot;off&quot;) + 
  scale_fill_viridis(discrete = TRUE) +
    theme_ipsum() +
    theme(axis.line = element_line(colour = &quot;black&quot;),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
      legend.position=&quot;none&quot;,
      plot.title = element_text(size=11)
    ) +
    ggtitle(&quot;Discrimination scores in both conditions&quot;, subtitle = expresion$expression[[1]]) +
    xlab(&quot;&quot;) + 
    ylab(&quot;Discrimination scores&quot;) + scale_fill_brewer(palette=&quot;Dark2&quot;) + scale_fill_manual(values = c(&quot;#56B4E9&quot;, &quot;#D55E00&quot;)) </code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
</div>
<div id="otros-gráficos" class="section level2">
<h2>7.3. Otros gráficos</h2>
<pre class="r"><code>library(dabestr)

two.group &lt;- 
  data %&gt;%
  dabest(condition, discrimination, 
         idx = c(&quot;Chaos condition&quot;, &quot;Order condition&quot;), 
         paired = FALSE)

two.group.meandiff &lt;- mean_diff(two.group)

plot(two.group.meandiff, rawplot.ylabel = &quot;Discrimation scores&quot;, rawplot.markersize = 3)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre class="r"><code>two.group.effsize &lt;- cohens_d(two.group)

plot(two.group.effsize, rawplot.ylabel = &quot;Discrimation scores&quot;, rawplot.markersize = 1.5)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-27-2.png" width="672" /></p>
</div>
<div id="guardar-los-gráficos" class="section level2">
<h2>7.4. Guardar los gráficos</h2>
<p>Primero guardamos el gráfico como un objeto, por ejemplo el que hemos hecho que combina el boxplot con el violinplot.</p>
<pre class="r"><code>Grafico &lt;- ggplot(data, aes(x = condition, y = discrimination, fill = condition)) +  ggdist::stat_halfeye(
    adjust = .5, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA) + 
  geom_boxplot(
    width = .20, 
    outlier.shape = NA) +
  geom_point(
    size = 2,
    alpha = .5,
    position = position_jitter(
      seed = 1, width = .1)) + 
  coord_cartesian(xlim = c(1.2, NA), clip = &quot;off&quot;) + 
  scale_fill_viridis(discrete = TRUE) +
    theme_ipsum() +
    theme(axis.line = element_line(colour = &quot;black&quot;),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
      legend.position=&quot;none&quot;,
      plot.title = element_text(size=11)
    ) +
    ggtitle(&quot;Discrimination scores in both conditions&quot;) +
    xlab(&quot;&quot;) + 
    ylab(&quot;Discrimination scores&quot;) + scale_fill_brewer(palette=&quot;Dark2&quot;) + scale_fill_manual(values = c(&quot;#56B4E9&quot;, &quot;#D55E00&quot;)) </code></pre>
<p>Luego cargamos el paquete library(jpeg) y establecemos nuestra dirección de trabajo si no lo hemos hecho antes.</p>
<pre class="r"><code>library(jpeg)


jpeg(file=&quot;Figure 1&quot;,width=2000,height=1400, units = &quot;px&quot;, res = 300) #Utilizamos la función especificando cómo queremos que sea la imagen
Grafico #Llamamos al objeto que hemos creado anteriormente
dev.off() #Lo cerramos</code></pre>
<p>Luego vamos a la carpeta donde esté guardado y cambiamos el nombre añadiendo .jpeg al final, indicando el formato.</p>
</div>
</div>
